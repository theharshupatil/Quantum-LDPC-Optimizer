{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9179b4d8-970b-4453-910c-ea5e241de016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Epoch 1: Train Loss=0.0398, Val Loss=0.0366\n",
      "Epoch 2: Train Loss=0.0342, Val Loss=0.0357\n",
      "Epoch 3: Train Loss=0.0329, Val Loss=0.0346\n",
      "Epoch 4: Train Loss=0.0319, Val Loss=0.0345\n",
      "Epoch 5: Train Loss=0.0310, Val Loss=0.0350\n",
      "Epoch 6: Train Loss=0.0298, Val Loss=0.0348\n",
      "Early stopping triggered\n",
      "Predictions shape: (11322, 8, 3)\n",
      "[[[7.9696274e-01 3.4359531e+03 1.3317471e+03]\n",
      "  [7.8824240e-01 3.4219531e+03 1.3751705e+03]\n",
      "  [7.9714757e-01 3.3065188e+03 1.4430303e+03]\n",
      "  ...\n",
      "  [7.9191023e-01 3.3162703e+03 1.4249875e+03]\n",
      "  [7.9928583e-01 3.4382871e+03 1.2764768e+03]\n",
      "  [8.0560917e-01 3.3522676e+03 1.4436274e+03]]\n",
      "\n",
      " [[7.8795505e-01 3.4276555e+03 1.3695000e+03]\n",
      "  [7.9685938e-01 3.3057419e+03 1.4452045e+03]\n",
      "  [7.9711235e-01 3.4107690e+03 1.3280752e+03]\n",
      "  ...\n",
      "  [7.9999328e-01 3.4567134e+03 1.2601501e+03]\n",
      "  [8.0300480e-01 3.3362415e+03 1.4570479e+03]\n",
      "  [8.0894941e-01 3.4996064e+03 1.2608839e+03]]\n",
      "\n",
      " [[7.9820353e-01 3.3210222e+03 1.4311028e+03]\n",
      "  [7.9743361e-01 3.4094126e+03 1.3285214e+03]\n",
      "  [7.9197371e-01 3.3866975e+03 1.4114370e+03]\n",
      "  ...\n",
      "  [8.0283672e-01 3.3280083e+03 1.4676781e+03]\n",
      "  [8.1212074e-01 3.5583889e+03 1.2161713e+03]\n",
      "  [7.9832053e-01 3.3387163e+03 1.4235920e+03]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[8.1340581e-01 3.3268840e+03 1.4837821e+03]\n",
      "  [8.1294590e-01 3.5476033e+03 1.2317858e+03]\n",
      "  [8.4164232e-01 4.0409722e+03 7.1075616e+02]\n",
      "  ...\n",
      "  [8.4105164e-01 3.8906401e+03 9.1516919e+02]\n",
      "  [8.2835180e-01 3.7635598e+03 9.6645020e+02]\n",
      "  [8.0373716e-01 3.2888938e+03 1.5097145e+03]]\n",
      "\n",
      " [[8.1250584e-01 3.5403723e+03 1.2334373e+03]\n",
      "  [8.4030646e-01 4.0441284e+03 7.0349945e+02]\n",
      "  [8.4304291e-01 3.9517866e+03 7.9194415e+02]\n",
      "  ...\n",
      "  [8.2820213e-01 3.7705847e+03 9.6477930e+02]\n",
      "  [8.2057804e-01 3.5592444e+03 1.2365503e+03]\n",
      "  [8.1484860e-01 3.6749524e+03 1.0588363e+03]]\n",
      "\n",
      " [[8.4088498e-01 4.0486062e+03 6.9272174e+02]\n",
      "  [8.4400612e-01 3.9562175e+03 7.8482819e+02]\n",
      "  [8.4384882e-01 3.9145959e+03 9.0977869e+02]\n",
      "  ...\n",
      "  [8.2540101e-01 3.6423396e+03 1.1579982e+03]\n",
      "  [8.2982123e-01 3.6759077e+03 1.0351689e+03]\n",
      "  [8.2248509e-01 3.6207000e+03 1.1672985e+03]]]\n"
     ]
    }
   ],
   "source": [
    "# --------------------------\n",
    "# 1️⃣ Imports\n",
    "# --------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import random\n",
    "\n",
    "# --------------------------\n",
    "# 2️⃣ Seed for reproducibility\n",
    "# --------------------------\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_everything()\n",
    "\n",
    "# --------------------------\n",
    "# 3️⃣ Device selection\n",
    "# --------------------------\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", DEVICE)\n",
    "\n",
    "# --------------------------\n",
    "# 4️⃣ Load data\n",
    "# --------------------------\n",
    "df = pd.read_csv(\"frames_errors.csv\", header=None)\n",
    "df.columns = [\n",
    "    \"block_id\",\"frame_idx\",\"E_mu_Z\",\"E_mu_phys_est\",\"E_mu_X\",\"E_nu1_X\",\"E_nu2_X\",\n",
    "    \"E_nu1_Z\",\"E_nu2_Z\",\"N_mu_X\",\"M_mu_XX\",\"M_mu_XZ\",\"M_mu_X\",\"N_mu_Z\",\"M_mu_ZZ\",\n",
    "    \"M_mu_Z\",\"N_nu1_X\",\"M_nu1_XX\",\"M_nu1_XZ\",\"M_nu1_X\",\"N_nu1_Z\",\"M_nu1_ZZ\",\"M_nu1_Z\",\n",
    "    \"N_nu2_X\",\"M_nu2_XX\",\"M_nu2_XZ\",\"M_nu2_X\",\"N_nu2_Z\",\"M_nu2_ZZ\",\"M_nu2_Z\",\"nTot\",\n",
    "    \"bayesImVoltage\",\"opticalPower\",\"polarizerVoltages[0]\",\"polarizerVoltages[1]\",\n",
    "    \"polarizerVoltages[2]\",\"polarizerVoltages[3]\",\"temp_1\",\"biasVoltage_1\",\"temp_2\",\n",
    "    \"biasVoltage_2\",\"synErr\",\"N_EC_rounds\",\"maintenance_flag\",\"estimator_name\",\n",
    "    \"f_EC\",\"E_mu_Z_est\",\"R\",\"s\",\"p\"\n",
    "]\n",
    "\n",
    "# Drop columns not used\n",
    "df_base = df.drop([\"E_mu_phys_est\", \"f_EC\", \"estimator_name\"], axis=1)\n",
    "\n",
    "# --------------------------\n",
    "# 5️⃣ Normalize features and targets\n",
    "# --------------------------\n",
    "features = df_base.drop(columns=[\"R\", \"s\", \"p\", \"block_id\", \"frame_idx\"]).values\n",
    "targets = df_base[[\"R\", \"s\", \"p\"]].values\n",
    "\n",
    "# Feature scaling\n",
    "scaler_X = StandardScaler()\n",
    "features_scaled = scaler_X.fit_transform(features)\n",
    "\n",
    "# Target scaling (MinMax for [0,1])\n",
    "scaler_y = MinMaxScaler()\n",
    "targets_scaled = scaler_y.fit_transform(targets)\n",
    "\n",
    "# Add series id and frame_idx back\n",
    "series_ids = df_base[\"block_id\"].values\n",
    "frame_idx = df_base[\"frame_idx\"].values\n",
    "\n",
    "# --------------------------\n",
    "# 6️⃣ Time series dataset class\n",
    "# --------------------------\n",
    "HISTORY = 300\n",
    "HORIZON = 8\n",
    "\n",
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, features, targets, series_ids, history=HISTORY, horizon=HORIZON):\n",
    "        self.X, self.y, self.series = [], [], []\n",
    "        self.history = history\n",
    "        self.horizon = horizon\n",
    "        unique_ids = np.unique(series_ids)\n",
    "        for uid in unique_ids:\n",
    "            idx = np.where(series_ids == uid)[0]\n",
    "            for i in range(len(idx) - history - horizon):\n",
    "                self.X.append(features[idx[i:i+history]])\n",
    "                self.y.append(targets[idx[i+history:i+history+horizon]])\n",
    "                self.series.append(uid)\n",
    "        self.X = np.array(self.X, dtype=np.float32)\n",
    "        self.y = np.array(self.y, dtype=np.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "# Split train/val/test 70/15/15\n",
    "unique_ids = np.unique(series_ids)\n",
    "n_train = int(len(unique_ids)*0.7)\n",
    "n_val = int(len(unique_ids)*0.15)\n",
    "\n",
    "train_ids = unique_ids[:n_train]\n",
    "val_ids = unique_ids[n_train:n_train+n_val]\n",
    "test_ids = unique_ids[n_train+n_val:]\n",
    "\n",
    "train_mask = np.isin(series_ids, train_ids)\n",
    "val_mask = np.isin(series_ids, val_ids)\n",
    "test_mask = np.isin(series_ids, test_ids)\n",
    "\n",
    "train_dataset = TimeSeriesDataset(features_scaled[train_mask], targets_scaled[train_mask], series_ids[train_mask])\n",
    "val_dataset = TimeSeriesDataset(features_scaled[val_mask], targets_scaled[val_mask], series_ids[val_mask])\n",
    "test_dataset = TimeSeriesDataset(features_scaled[test_mask], targets_scaled[test_mask], series_ids[test_mask])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# --------------------------\n",
    "# 7️⃣ FEDformer model (simplified)\n",
    "# --------------------------\n",
    "class FourierBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, seq_len):\n",
    "        super(FourierBlock, self).__init__()\n",
    "        self.weights = nn.Parameter(torch.randn(in_channels, out_channels, dtype=torch.cfloat))\n",
    "        self.seq_len = seq_len\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_ft = torch.fft.rfft(x, dim=1)\n",
    "        out_ft = torch.einsum(\"bsi,io->bso\", x_ft, self.weights)\n",
    "        x = torch.fft.irfft(out_ft, n=self.seq_len, dim=1)\n",
    "        return x\n",
    "\n",
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, d_ff, seq_len):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.attn = FourierBlock(d_model, d_model, seq_len)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.ff = nn.Sequential(nn.Linear(d_model, d_ff), nn.GELU(), nn.Linear(d_ff, d_model))\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.norm1(x + self.attn(x))\n",
    "        x = self.norm2(x + self.ff(x))\n",
    "        return x\n",
    "\n",
    "class FEDformer(nn.Module):\n",
    "    def __init__(self, seq_len, pred_len, d_model=64, d_ff=128, e_layers=2, enc_in=features.shape[1], c_out=3):\n",
    "        super(FEDformer, self).__init__()\n",
    "        self.seq_len = seq_len\n",
    "        self.pred_len = pred_len\n",
    "        self.enc_embedding = nn.Linear(enc_in, d_model)\n",
    "        self.encoder = nn.ModuleList([EncoderLayer(d_model, d_ff, seq_len) for _ in range(e_layers)])\n",
    "        self.projection = nn.Linear(d_model, c_out)\n",
    "\n",
    "    def forward(self, x_enc):\n",
    "        x = self.enc_embedding(x_enc)\n",
    "        for layer in self.encoder:\n",
    "            x = layer(x)\n",
    "        out = self.projection(x[:, -self.pred_len:, :])\n",
    "        return out\n",
    "\n",
    "# --------------------------\n",
    "# 8️⃣ Train loop\n",
    "# --------------------------\n",
    "def train_model(model, train_loader, val_loader, n_epochs=5, lr=1e-3, patience=2):\n",
    "    model = model.to(DEVICE)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.MSELoss()\n",
    "    best_val = float('inf')\n",
    "    counter = 0\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for X, y in train_loader:\n",
    "            X, y = X.to(DEVICE), y.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(X)\n",
    "            loss = criterion(y_pred, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * X.size(0)\n",
    "\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for X, y in val_loader:\n",
    "                X, y = X.to(DEVICE), y.to(DEVICE)\n",
    "                y_pred = model(X)\n",
    "                val_loss += criterion(y_pred, y).item() * X.size(0)\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}: Train Loss={train_loss:.4f}, Val Loss={val_loss:.4f}\")\n",
    "\n",
    "        # Early stopping\n",
    "        if val_loss < best_val:\n",
    "            best_val = val_loss\n",
    "            counter = 0\n",
    "            torch.save(model.state_dict(), \"fedformer_best.pt\")\n",
    "        else:\n",
    "            counter += 1\n",
    "            if counter >= patience:\n",
    "                print(\"Early stopping triggered\")\n",
    "                break\n",
    "\n",
    "    model.load_state_dict(torch.load(\"fedformer_best.pt\"))\n",
    "    return model\n",
    "\n",
    "# --------------------------\n",
    "# 9️⃣ Train\n",
    "# --------------------------\n",
    "model = FEDformer(seq_len=HISTORY, pred_len=HORIZON)\n",
    "model = train_model(model, train_loader, val_loader, n_epochs=20, lr=1e-3)\n",
    "\n",
    "# --------------------------\n",
    "# 10️⃣ Predict & inverse transform\n",
    "# --------------------------\n",
    "model.eval()\n",
    "all_preds = []\n",
    "with torch.no_grad():\n",
    "    for X, y in test_loader:\n",
    "        X = X.to(DEVICE)\n",
    "        preds = model(X)\n",
    "        all_preds.append(preds.cpu().numpy())\n",
    "\n",
    "all_preds = np.concatenate(all_preds, axis=0)\n",
    "all_preds_inv = scaler_y.inverse_transform(all_preds.reshape(-1,3)).reshape(all_preds.shape)\n",
    "\n",
    "print(\"Predictions shape:\", all_preds_inv.shape)\n",
    "print(all_preds_inv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07781327-f31e-4eb3-bc94-7e32c47592e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_preds_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a647ae-7fcb-4a61-bde6-e8a7bcadb39c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
