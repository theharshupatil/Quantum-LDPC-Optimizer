{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a001f193-73df-4c4a-ac37-a819e56daead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# E3.ipynb\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import root_mean_squared_error, r2_score\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df82087d-74ca-4f27-ad2d-24606b226b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To ensure reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Read data from Excel file\n",
    "file_path = 'E3.xlsx'\n",
    "train_data = pd.read_excel(file_path, sheet_name='train')\n",
    "test_data = pd.read_excel(file_path, sheet_name='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe041be9-ab90-4777-b06a-2bae3674aec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target variable in train data\n",
    "X_train = train_data.drop(columns=['y'])\n",
    "y_train = train_data['y']\n",
    "\n",
    "# Separate features and target variable in test data\n",
    "X_test = test_data.drop(columns=['y'])\n",
    "y_test = test_data['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b11e0a-c7e8-4ca4-8863-c7910c515e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Adding outliers (UNCOMMENT ONLY WHEN REQUIRED! SEE THE PROBLEM STATEMENTs ...)\n",
    "# X_train = np.array(list(X_train['x1']) + [X_train['x1'].mean() + x for x in np.random.randn(5)]).reshape(-1,1)\n",
    "# y_train = np.array(list(y_train) + [y_train.max() + 4 + x for x in np.random.randn(5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c43fa0b-d569-41b0-8764-8879315741fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use PolynomialFeatures to create features\n",
    "poly = PolynomialFeatures(degree=1)\n",
    "X_train_poly = poly.fit_transform(X_train)\n",
    "X_test_poly = poly.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dadd0de-0235-44bd-ad6b-8b2394d41003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardization of the data\n",
    "scaler = StandardScaler()\n",
    "X_train_poly = scaler.fit_transform(X_train_poly)\n",
    "X_test_poly = scaler.transform(X_test_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53759320-3b13-4f34-9eed-1dd9a8edafb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "# Save the augmented data set to a file for review\n",
    "\n",
    "# Create dataframe with test data and additional features\n",
    "# Get feature names\n",
    "feature_names = poly.get_feature_names_out()\n",
    "augmented_data = pd.DataFrame(X_train_poly, columns=feature_names)\n",
    "augmented_data['y'] = train_data['y']\n",
    "\n",
    "# # Write dataframe to CSV\n",
    "augmented_data.to_csv('augmented_train_data.csv', index=False)\n",
    "####################################\n",
    "####################################\n",
    "# Save the augmented data set to a file for review\n",
    "\n",
    "# Create dataframe with test data and additional features\n",
    "# Get feature names\n",
    "feature_names = poly.get_feature_names_out()\n",
    "augmented_data = pd.DataFrame(X_test_poly, columns=feature_names)\n",
    "augmented_data['y'] = test_data['y']\n",
    "\n",
    "# # Write dataframe to CSV\n",
    "augmented_data.to_csv('augmented_test_data.csv', index=False)\n",
    "####################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ce30fe-c1b7-4632-90d0-a1e95190ef42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algorithms\n",
    "algorithms = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'SVM Regression': SVR(kernel='poly'),  # Adjust kernel as needed\n",
    "    'RandomForest': RandomForestRegressor(),\n",
    "    'XGBoost': GradientBoostingRegressor(),\n",
    "    'knn': KNeighborsRegressor(),\n",
    "    'Neural Network-10': MLPRegressor(hidden_layer_sizes=[10], max_iter=20000),\n",
    "}\n",
    "\n",
    "# Metric tables\n",
    "metric_table_train = pd.DataFrame()\n",
    "metric_table_test = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c43053",
   "metadata": {
    "id": "10c43053"
   },
   "outputs": [],
   "source": [
    "# Create a grid of subplots\n",
    "fig, axs = plt.subplots(len(algorithms), 4, figsize=(20, 4 * len(algorithms)))\n",
    "fig_row = -1\n",
    "\n",
    "# Run the algorithms ... create metrics and plots\n",
    "for algorithm_name, algorithm in algorithms.items():\n",
    "\n",
    "    # Train model\n",
    "    algorithm.fit(X_train_poly, y_train)\n",
    "\n",
    "    # Train predictions\n",
    "    y_train_pred = algorithm.predict(X_train_poly)\n",
    "\n",
    "    # Test predictions\n",
    "    y_test_pred = algorithm.predict(X_test_poly)\n",
    "\n",
    "    # Train metrics\n",
    "    r2_train = algorithm.score(X_train_poly, y_train)\n",
    "    rmse_train = root_mean_squared_error(y_train, y_train_pred)\n",
    "\n",
    "    # Test metrics\n",
    "    r2_test = algorithm.score(X_test_poly, y_test)\n",
    "    rmse_test = root_mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "    # Additional metrics using statsmodels for all algorithms\n",
    "    residuals_train = y_train - y_train_pred\n",
    "    residuals_test = y_test - y_test_pred\n",
    "\n",
    "    durbin_watson_stat_train = sm.stats.durbin_watson(residuals_train)\n",
    "    jb_stat_train, jb_p_value_train, _, _ = sm.stats.jarque_bera(residuals_train)\n",
    "\n",
    "    durbin_watson_stat_test = sm.stats.durbin_watson(residuals_test)\n",
    "    jb_stat_test, jb_p_value_test, _, _ = sm.stats.jarque_bera(residuals_test)\n",
    "\n",
    "    # Update metric tables\n",
    "    metric_table_train.at[algorithm_name, 'R-squared'] = r2_train\n",
    "    metric_table_train.at[algorithm_name, 'RMSE'] = rmse_train\n",
    "    metric_table_train.at[algorithm_name, 'Durbin-Watson'] = durbin_watson_stat_train\n",
    "    metric_table_train.at[algorithm_name, 'Jarque-Bera'] = jb_stat_train\n",
    "    metric_table_train.at[algorithm_name, 'JB P-value'] = jb_p_value_train\n",
    "\n",
    "    metric_table_test.at[algorithm_name, 'R-squared'] = r2_test\n",
    "    metric_table_test.at[algorithm_name, 'RMSE'] = rmse_test\n",
    "    metric_table_test.at[algorithm_name, 'Durbin-Watson'] = durbin_watson_stat_test\n",
    "    metric_table_test.at[algorithm_name, 'Jarque-Bera'] = jb_stat_test\n",
    "    metric_table_test.at[algorithm_name, 'JB P-value'] = jb_p_value_test\n",
    "\n",
    "    # Create the plots\n",
    "    fig_row = fig_row+1\n",
    "\n",
    "    axs[fig_row, 0].scatter(X_train, y_train)\n",
    "    axs[fig_row, 0].scatter(X_train, y_train_pred)\n",
    "    axs[fig_row, 0].set_title(algorithm_name + \" - Train\")\n",
    "\n",
    "    axs[fig_row, 1].scatter(X_train, residuals_train)\n",
    "    axs[fig_row, 1].set_title(algorithm_name + \" Residuals - Train\")\n",
    "\n",
    "    axs[fig_row, 2].scatter(X_test, y_test)\n",
    "    axs[fig_row, 2].scatter(X_test, y_test_pred)\n",
    "    axs[fig_row, 2].set_title(algorithm_name + \" - Test\")\n",
    "\n",
    "    axs[fig_row, 3].scatter(X_test, residuals_test)\n",
    "    axs[fig_row, 3].set_title(algorithm_name + \" Residuals - Test\")\n",
    "############################\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bbfb1a",
   "metadata": {
    "id": "42bbfb1a"
   },
   "outputs": [],
   "source": [
    "# Display the metrics' Tables\n",
    "print(\"Metrics - Train Data:\\n\")\n",
    "print(metric_table_train.to_string())\n",
    "print(\"-------------------------------------------------\")\n",
    "\n",
    "print(\"Metrics - Test Data:\\n\")\n",
    "print(metric_table_test.to_string())"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
